version: "3.9"
services:
  #needed to allow access to host's docker daemon while integration testing in multistage build
  testcontainers_bridge_to_docker_daemon_on_host:
    ports:
      - "127.0.0.1:2375:2375"
    volumes:
      - //var/run/docker.sock://var/run/docker.sock
    image: alpine/socat
    command: tcp-listen:2375,reuseaddr,fork unix-connect:/var/run/docker.sock

  library_instance:
    container_name: lib_container
    hostname: service
    build:
      context: ../../../
      dockerfile: src/main/docker/lib-service/dockerfile-multistage
    env_file:
      - compose.env
    environment:
      envs.port: ${SERVER_PORT}
      envs.debug.query: ${QUERY_LOGGING}
      envs.debug.param: ${QUERY_PARAM_LOGGING}
      envs.database.name: ${DB_NAME}
      envs.database.username: ${DB_USERNAME}
      envs.database.password: ${DB_PASSWORD}
      SPRINGPROFILES: "actuator,default"
      ###todo somehow cant move this to env variable, need to investigate
      ###todo appears to not work at all
      spring.r2dbc.url: r2dbc:pool:postgres://postgres_db/movies-db
      spring.r2dbc.name: dev
      spring.r2dbc.password: dev123
      spring.kafka.bootstrap-servers: broker:29092
    ports:
      - "8083:8083"
    restart: always
    healthcheck:
      test: wget --no-verbose --tries=1 --spider localhost:${SERVER_PORT}/actuator/health || exit 1
      interval: 5s
      timeout: 2s
      retries: 3
      start_period: 10s
    depends_on:
      - elasticsearch
      - postgres_db
      - testcontainers_bridge_to_docker_daemon_on_host

  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  broker:
    image: confluentinc/cp-kafka:7.5.0
    hostname: broker
    container_name: broker
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "9101:9101"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT,PLAINTEXT2:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092 #,PLAINTEXT2://service:8083
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost


  postgres_db:
    image: postgres:14.8-alpine3.18
    command:
      - "postgres"
      - "-c"
      - "max_connections=50"
      - "-c"
      - "shared_buffers=1GB"
      - "-c"
      - "effective_cache_size=4GB"
      - "-c"
      - "work_mem=16MB"
      - "-c"
      - "maintenance_work_mem=512MB"
      - "-c"
      - "random_page_cost=1.1"
      - "-c"
      - "temp_file_limit=10GB"
      - "-c"
      - "log_min_duration_statement=200ms"
      - "-c"
      - "idle_in_transaction_session_timeout=10s"
      - "-c"
      - "lock_timeout=1s"
      - "-c"
      - "statement_timeout=60s"
      - "-c"
      - "shared_preload_libraries=pg_stat_statements"
      - "-c"
      - "pg_stat_statements.max=10000"
      - "-c"
      - "pg_stat_statements.track=all"
    env_file:
      - .env
    environment:
      POSTGRES_DB: ${DB_NAME}
      POSTGRES_USER: ${DB_USERNAME}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      PGDATA: "/var/lib/postgresql/data/pgdata"
    volumes:
      - ./docker-db/data/db-data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U $DB_USERNAME -d $DB_NAME" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 4G

  flyway:
    image: flyway/flyway:10
    command: -locations=filesystem:/flyway/sql -connectRetries=60 migrate
    env_file:
      - .env
    volumes:
      - ./docker-db/flyway/migrations:/flyway/sql
    environment:
      - FLYWAY_USER=${DB_USERNAME}
      - FLYWAY_PASSWORD=${DB_PASSWORD}
      - FLYWAY_URL=jdbc:postgresql://postgres_db/${DB_NAME}
    depends_on:
      - postgres_db


  pgadmin:
    hostname: admin_console
    container_name: pgadmin_container
    image: dpage/pgadmin4:7.2
    depends_on:
      - postgres_db
    environment:
      PGADMIN_DEFAULT_EMAIL: ${DB_USERNAME}@gmail.com
      PGADMIN_DEFAULT_PASSWORD: ${DB_PASSWORD}
      PGADMIN_CONFIG_SERVER_MODE: "False"
    volumes:
      - ./docker-db/data/pgadmin-data:/var/lib/pgadmin
    ports:
      - "5050:80"
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1G

  grafana:
    build: './monitoring/grafana'
    ports:
      - 3000:3000
    volumes:
      - ./monitoring/grafana-data:/var/lib/grafana
    env_file:
      - compose.env
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_USER}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}

  prometheus:
    image: prom/prometheus
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./monitoring/prometheus-data:/prometheus
    extra_hosts:
      - "host.docker.internal:host-gateway"

  setup:
    build:
      context: docker-elk/setup/
      args:
        ELASTIC_VERSION: ${ELASTIC_VERSION}
    init: true
    volumes:
      - ./docker-elk/setup/entrypoint.sh:/entrypoint.sh:ro,Z
      - ./docker-elk/setup/helpers.sh:/helpers.sh:ro,Z
      - ./docker-elk/setup/roles:/roles:ro,Z
      - setup:/state:Z
    environment:
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD:-}
      LOGSTASH_INTERNAL_PASSWORD: ${LOGSTASH_INTERNAL_PASSWORD:-}
      KIBANA_SYSTEM_PASSWORD: ${KIBANA_SYSTEM_PASSWORD:-}
      METRICBEAT_INTERNAL_PASSWORD: ${METRICBEAT_INTERNAL_PASSWORD:-}
      FILEBEAT_INTERNAL_PASSWORD: ${FILEBEAT_INTERNAL_PASSWORD:-}
      HEARTBEAT_INTERNAL_PASSWORD: ${HEARTBEAT_INTERNAL_PASSWORD:-}
      MONITORING_INTERNAL_PASSWORD: ${MONITORING_INTERNAL_PASSWORD:-}
      BEATS_SYSTEM_PASSWORD: ${BEATS_SYSTEM_PASSWORD:-}
    depends_on:
      - elasticsearch

  elasticsearch:
    build:
      context: docker-elk/elasticsearch/
      args:
        ELASTIC_VERSION: ${ELASTIC_VERSION}
    volumes:
      - ./docker-elk/elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro,Z
      - elasticsearch:/usr/share/elasticsearch/data:Z
    ports:
      - 9200:9200
      - 9300:9300
    environment:
      node.name: elasticsearch
      ES_JAVA_OPTS: -Xms512m -Xmx512m
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD:-}
      discovery.type: single-node

  kibana:
    build:
      context: docker-elk/kibana/
      args:
        ELASTIC_VERSION: ${ELASTIC_VERSION}
    volumes:
      - ./docker-elk/kibana/config/kibana.yml:/usr/share/kibana/config/kibana.yml:ro,Z
    ports:
      - 5601:5601
    environment:
      KIBANA_SYSTEM_PASSWORD: ${KIBANA_SYSTEM_PASSWORD:-}
    depends_on:
      - elasticsearch

  logstash:
    #    image: library/logstash
    build:
      context: docker-elk/logstash/
      args:
        ELASTIC_VERSION: ${ELASTIC_VERSION}
    volumes:
      - ./docker-elk/logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml
      - ./docker-elk/logstash/pipeline:/usr/share/logstash/pipeline
      - /mnt/c/temp/logs:/usr/share/logstash/logs
    ports:
      - 5044:5044
      - 50000:50000/tcp
      - 50000:50000/udp
      - 9600:9600
    environment:
      LOG_LEVEL: debug
      LS_JAVA_OPTS: -Xms256m -Xmx256m
      LOGSTASH_INTERNAL_PASSWORD: ${LOGSTASH_INTERNAL_PASSWORD:-}
    depends_on:
      - elasticsearch

volumes:
  setup:
  elasticsearch: